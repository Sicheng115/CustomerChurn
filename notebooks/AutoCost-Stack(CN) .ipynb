{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d62ade7-9481-4aad-8042-b9be5e7ba826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 环境与基础导入\n",
    "# =========================\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import OneHotEncoder, QuantileTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score, precision_recall_curve,\n",
    "    brier_score_loss, precision_score, recall_score\n",
    ")\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# 可选：如安装了 xgboost / catboost，会自动启用；未安装则跳过\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    HAS_CAT = True\n",
    "except Exception:\n",
    "    HAS_CAT = False\n",
    "\n",
    "SEED = 2025\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3811751-d041-4872-aa14-54fb4564b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载数据：churn_clean.csv   形状=(10000, 11)\n",
      "特征列数： 10 ；示例列： ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 数据加载 + 目标变量统一\n",
    "# ==================================\n",
    "\n",
    "DATA_PATH = 'churn_clean.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"已加载数据：{DATA_PATH}   形状={df.shape}\")\n",
    "\n",
    "# 统一目标：y=1 表示流失\n",
    "if \"Exited\" in df.columns:\n",
    "    y = df[\"Exited\"].astype(int).values\n",
    "    X = df.drop(columns=[\"Exited\"]).copy()\n",
    "elif \"Attrition_Flag\" in df.columns:\n",
    "    y = (df[\"Attrition_Flag\"].astype(str).str.lower().str.contains(\"attrited\")).astype(int).values\n",
    "    X = df.drop(columns=[\"Attrition_Flag\"]).copy()\n",
    "elif \"Churn\" in df.columns:\n",
    "    y = df[\"Churn\"]\n",
    "    if y.dtype.kind in \"biu\":\n",
    "        y = y.astype(int).values\n",
    "    else:\n",
    "        y = y.astype(str).str.lower().isin([\"1\", \"yes\", \"true\", \"churn\"]).astype(int).values\n",
    "    X = df.drop(columns=[\"Churn\"]).copy()\n",
    "else:\n",
    "    raise ValueError(\"未识别的目标列，请手工指定。\")\n",
    "\n",
    "# 去除明显的ID/无信息列（若存在）\n",
    "drop_cols = [c for c in [\n",
    "    \"RowNumber\",\"CustomerId\",\"CustomerID\",\"customerID\",\"CLIENTNUM\",\n",
    "    \"Surname\",\"Id\",\"ID\",\"Unnamed: 0\",\"Unnamed: 0.1\"\n",
    "] if c in X.columns]\n",
    "if drop_cols:\n",
    "    X = X.drop(columns=drop_cols)\n",
    "\n",
    "print(\"特征列数：\", X.shape[1], \"；示例列：\", list(X.columns)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adb419c-9788-4f9e-905a-9ae48dd4d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数值列 8 个；类别列 2 个。\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 特征类型识别 + 通用预处理器\n",
    "# 数值：中位数填充 + 分位数变换（抗极端值）\n",
    "# 类别：众数填充 + OneHot\n",
    "# ========================================\n",
    "# 将布尔型统一为 object 以便 OneHot（如果你更希望当成数值，也可以改）\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == bool:\n",
    "        X[c] = X[c].astype(object)\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"qtf\", QuantileTransformer(output_distribution=\"normal\", subsample=2_000_000, n_quantiles=min(1000, max(10, len(X)//5)))),\n",
    "])\n",
    "\n",
    "# 兼容老/新 sklearn：sparse=False 或 sparse_output=False 二选一\n",
    "try:\n",
    "    cat_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    cat_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", cat_encoder),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "print(f\"数值列 {len(num_cols)} 个；类别列 {len(cat_cols)} 个。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15700b1e-8223-4c46-974a-8b7532f3fa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>cust_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0.220513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0.433502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0.751582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0.176011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0.513615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  cust_value  \n",
       "0          1               1        101348.88    0.220513  \n",
       "1          0               1        112542.58    0.433502  \n",
       "2          1               0        113931.57    0.751582  \n",
       "3          0               0         93826.63    0.176011  \n",
       "4          1               1         79084.10    0.513615  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 构造客户价值 v_i（可解释、可复现）\n",
    "# - 自动在常见列中择优选择；若没有则退化为选择前若干数值列\n",
    "# - 每个分量做 1%~99% 分位截尾 + [0,1] 归一化\n",
    "# - 再按权重加权求和，最终再归一化到 [0,1]\n",
    "# ============================================\n",
    "def compute_customer_value(df_features: pd.DataFrame) -> pd.Series:\n",
    "    df_ = df_features.copy()\n",
    "\n",
    "    # Kaggle Churn_Modelling 的优先字段及权重---可学习\n",
    "    main_scheme = [\n",
    "        (\"Balance\", 0.45),\n",
    "        (\"EstimatedSalary\", 0.20),\n",
    "        (\"NumOfProducts\", 0.15),\n",
    "        (\"Tenure\", 0.10),\n",
    "        (\"IsActiveMember\", 0.10),\n",
    "    ]\n",
    "\n",
    "    # BankChurners 的备选字段及权重\n",
    "    alt_scheme = [\n",
    "        (\"Total_Trans_Amt\", 0.40),\n",
    "        (\"Credit_Limit\", 0.20),\n",
    "        (\"Total_Trans_Ct\", 0.15),\n",
    "        (\"Total_Relationship_Count\", 0.10),\n",
    "        (\"Months_on_book\", 0.10),\n",
    "        (\"Avg_Utilization_Ratio\", 0.05),\n",
    "    ]\n",
    "\n",
    "    # 选择可用的方案\n",
    "    scheme = [(c, w) for c, w in main_scheme if c in df_.columns]\n",
    "    if len(scheme) < 3:\n",
    "        scheme = [(c, w) for c, w in alt_scheme if c in df_.columns]\n",
    "\n",
    "    # 若数据集完全不同，退化为前若干数值列等权\n",
    "    if len(scheme) == 0:\n",
    "        num_candidates = df_.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        # 避免把目标泄露进来，这里只用 X 的列，不包含 y\n",
    "        num_candidates = [c for c in num_candidates]\n",
    "        num_candidates = num_candidates[:min(6, len(num_candidates))]\n",
    "        scheme = [(c, 1.0) for c in num_candidates]\n",
    "\n",
    "    components = []\n",
    "    weights = []\n",
    "    for col, w in scheme:\n",
    "        s = pd.to_numeric(df_[col], errors=\"coerce\")\n",
    "        s = s.fillna(s.median())\n",
    "        q1, q99 = s.quantile([0.01, 0.99])\n",
    "        s = s.clip(q1, q99)\n",
    "        s = (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
    "        components.append(s.values)\n",
    "        weights.append(w)\n",
    "\n",
    "    weights = np.asarray(weights, dtype=float)\n",
    "    if weights.sum() == 0:\n",
    "        weights = np.ones_like(weights)\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    V = np.zeros(len(df_), dtype=float)\n",
    "    for comp, w in zip(components, weights):\n",
    "        V += w * comp\n",
    "\n",
    "    V = (V - V.min()) / (V.max() - V.min() + 1e-9)\n",
    "    return pd.Series(V, index=df_.index, name=\"cust_value\")\n",
    "\n",
    "# 计算并附加到 X，便于分析（模型输入不一定使用该列，这里主要用于 sample_weight 与指标）\n",
    "cust_value_all = compute_customer_value(X)\n",
    "X_with_value = X.copy()\n",
    "X_with_value[\"cust_value\"] = cust_value_all\n",
    "X_with_value.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5f461c-4f61-4ea3-bf05-56a47a3407ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： (8000, 10) ；测试集大小： (2000, 10)\n",
      "类别权重： {0: 0.6279434850863422, 1: 2.4539877300613497}\n",
      "样本权重示例（前5个）： [0.96808298 0.809095   0.82696893 3.85786522 0.90799112]\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# 切分训练/测试 + 计算样本权重\n",
    "# w_i = class_weight[y_i] * (1 + gamma * v_i)\n",
    "# gamma 控制价值权重强度，默认 1.0，可调\n",
    "# ===========================================\n",
    "gamma = 1.0  # 可以调成 0.5~2.0 观察敏感性\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_with_value.drop(columns=[\"cust_value\"]),\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y\n",
    ")\n",
    "v_train = cust_value_all.loc[X_train.index]  # 与训练样本对齐的客户价值\n",
    "v_test  = cust_value_all.loc[X_test.index]\n",
    "\n",
    "# 类别不平衡权重\n",
    "cls_w = compute_class_weight(class_weight=\"balanced\", classes=np.array([0, 1]), y=y_train)\n",
    "class_weight_dict = {0: cls_w[0], 1: cls_w[1]}\n",
    "\n",
    "# 样本权重\n",
    "sample_weight_train = np.array([class_weight_dict[int(yi)] * (1.0 + gamma * vi)\n",
    "                                for yi, vi in zip(y_train, v_train)], dtype=float)\n",
    "\n",
    "print(\"训练集大小：\", X_train.shape, \"；测试集大小：\", X_test.shape)\n",
    "print(\"类别权重：\", class_weight_dict)\n",
    "print(\"样本权重示例（前5个）：\", sample_weight_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d385fa8-25f6-4332-a82a-13eb900f54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 评估函数（价值指标 + 校准质量 + 利润阈值）\n",
    "# ===================================================\n",
    "def value_precision_recall_at_k(y_true, scores, v, k=0.1):\n",
    "    \"\"\"返回 (Value-Precision@K, Value-Recall@K, 价值覆盖率)\"\"\"\n",
    "    n = len(scores)\n",
    "    top = max(1, int(math.ceil(k * n)))\n",
    "    order = np.argsort(-scores)\n",
    "    sel = order[:top]\n",
    "    # Value-Precision@K：选中集合中真正流失的价值占选中价值的比例\n",
    "    vp = v[sel][(y_true[sel] == 1)].sum() / (v[sel].sum() + 1e-12)\n",
    "    # Value-Recall@K：选中集合中真正流失的价值占全部流失价值的比例\n",
    "    vr = v[sel][(y_true[sel] == 1)].sum() / (v[(y_true == 1)].sum() + 1e-12)\n",
    "    # 价值覆盖率：选中集合的总价值 / 全部价值\n",
    "    cov = v[sel].sum() / (v.sum() + 1e-12)\n",
    "    return float(vp), float(vr), float(cov)\n",
    "\n",
    "def value_pr_auc(y_true, scores, v):\n",
    "    \"\"\"价值加权 PR-AUC：对 precision_recall_curve 使用 sample_weight=v\"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(y_true, scores, sample_weight=v)\n",
    "    # AUC（梯形法则）\n",
    "    return float(np.trapz(precision, recall))\n",
    "\n",
    "def expected_calibration_error(y_true, prob, n_bins=15):\n",
    "    \"\"\"ECE：概率校准误差（等频分箱）\"\"\"\n",
    "    order = np.argsort(prob)\n",
    "    y_sorted = np.array(y_true)[order]\n",
    "    p_sorted = np.array(prob)[order]\n",
    "    bins = np.array_split(np.arange(len(prob)), n_bins)\n",
    "    ece = 0.0\n",
    "    for idx in bins:\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        yb = y_sorted[idx]\n",
    "        pb = p_sorted[idx]\n",
    "        conf = pb.mean()\n",
    "        acc = yb.mean()\n",
    "        ece += len(idx) / len(prob) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def search_tau_by_profit(scores, y_true, v, C_contact=1.0, gain=1.5, budget=0.1):\n",
    "    \"\"\"\n",
    "    在验证集或测试集上，以预算上限（Top-K 占比）为约束，搜索带来最高利润的阈值。\n",
    "    - scores：预测概率\n",
    "    - y_true：真实标签（0/1）\n",
    "    - v：客户价值（非负）\n",
    "    - C_contact：联系一个客户的成本\n",
    "    - gain：当 y=1 且被联系时的收益系数（收益 = gain * v_i）\n",
    "    - budget：最多联系的样本占比（0~1）\n",
    "    返回：best_tau, best_profit, profit_curve（DataFrame: k, tau, profit）\n",
    "    \"\"\"\n",
    "    n = len(scores)\n",
    "    order = np.argsort(-scores)\n",
    "    max_k = max(1, int(math.floor(budget * n)))\n",
    "    ks = np.arange(1, max_k + 1)\n",
    "\n",
    "    # 预先按分数排序后的 y 与 v\n",
    "    y_sorted = y_true[order]\n",
    "    v_sorted = v[order]\n",
    "    s_sorted = scores[order]\n",
    "\n",
    "    # 累计量，便于 O(1) 计算前 k 的利润\n",
    "    cum_tp_value = np.cumsum(v_sorted * (y_sorted == 1))\n",
    "    cum_all_cost = np.arange(1, n + 1) * C_contact\n",
    "\n",
    "    profits = gain * cum_tp_value[:max_k] - cum_all_cost[:max_k]\n",
    "    # 阈值取为第 k 个分数\n",
    "    taus = s_sorted[ks - 1]\n",
    "\n",
    "    best_idx = int(np.argmax(profits))\n",
    "    best_tau = float(taus[best_idx])\n",
    "    best_profit = float(profits[best_idx])\n",
    "\n",
    "    import pandas as pd\n",
    "    curve = pd.DataFrame({\"k\": ks, \"tau\": taus, \"profit\": profits})\n",
    "    return best_tau, best_profit, curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfcebde2-77b4-4fc2-815f-cfef67eb9fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR', 'RF_cal', 'HGB_cal', 'LinearSVM_cal']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 基模型（带校准）构造器（兼容 sklearn 新旧 API）\n",
    "# - 每个模型外面都包一层预处理 Pipeline\n",
    "# - 采用 CalibratedClassifierCV(method='isotonic' 或 'sigmoid')\n",
    "# ===================================================\n",
    "import inspect\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def calibrated(method=\"auto\"):\n",
    "    # 数据量较小时，用 'sigmoid' 更稳定；否则 'isotonic'\n",
    "    if method == \"auto\":\n",
    "        return \"isotonic\" if len(X_train) >= 2000 else \"sigmoid\"\n",
    "    return method\n",
    "\n",
    "def _build_calibrator(base_est, method=\"isotonic\", cv=3):\n",
    "    \"\"\"\n",
    "    兼容性封装：sklearn>=1.2 使用 estimator，旧版本使用 base_estimator\n",
    "    \"\"\"\n",
    "    params = inspect.signature(CalibratedClassifierCV).parameters\n",
    "    if \"estimator\" in params:  # 新版\n",
    "        return CalibratedClassifierCV(estimator=base_est, method=method, cv=cv)\n",
    "    else:                      # 旧版\n",
    "        return CalibratedClassifierCV(base_estimator=base_est, method=method, cv=cv)\n",
    "\n",
    "def make_base_models(preprocessor, class_weight_dict, seed=SEED):\n",
    "    models = {}\n",
    "\n",
    "    # 1) 逻辑回归（本身校准较好，这里不再套校准器）\n",
    "    lr = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=2000,\n",
    "            class_weight=class_weight_dict,\n",
    "            solver=\"lbfgs\"\n",
    "        ))\n",
    "    ])\n",
    "    models[\"LR\"] = lr\n",
    "\n",
    "    # 2) 随机森林 + 校准\n",
    "    rf_cal = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", _build_calibrator(\n",
    "            base_est=RandomForestClassifier(\n",
    "                n_estimators=400,\n",
    "                max_depth=None,\n",
    "                min_samples_leaf=2,\n",
    "                n_jobs=-1,\n",
    "                random_state=seed,\n",
    "                class_weight=class_weight_dict\n",
    "            ),\n",
    "            method=calibrated(),\n",
    "            cv=3\n",
    "        ))\n",
    "    ])\n",
    "    models[\"RF_cal\"] = rf_cal\n",
    "\n",
    "    # 3) 直方图GBDT（速度快）+ 校准\n",
    "    hgb_cal = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", _build_calibrator(\n",
    "            base_est=HistGradientBoostingClassifier(\n",
    "                max_depth=None,\n",
    "                learning_rate=0.06,\n",
    "                l2_regularization=0.0,\n",
    "                max_leaf_nodes=31,\n",
    "                random_state=seed\n",
    "            ),\n",
    "            method=calibrated(),\n",
    "            cv=3\n",
    "        ))\n",
    "    ])\n",
    "    models[\"HGB_cal\"] = hgb_cal\n",
    "\n",
    "    # 4) 线性 SVM + 校准（SVM 原生无概率）\n",
    "    lsvm_cal = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", _build_calibrator(\n",
    "            base_est=LinearSVC(\n",
    "                C=1.0,\n",
    "                class_weight=class_weight_dict,\n",
    "                random_state=seed\n",
    "            ),\n",
    "            method=\"sigmoid\",  # 对于线性 SVM 用 Platt 更稳\n",
    "            cv=3\n",
    "        ))\n",
    "    ])\n",
    "    models[\"LinearSVM_cal\"] = lsvm_cal\n",
    "\n",
    "    # 5) 可选：XGBoost + 校准（若已安装）\n",
    "    if HAS_XGB:\n",
    "        scale_pos_weight = class_weight_dict[1] / max(1e-9, class_weight_dict[0])\n",
    "        xgb_cal = Pipeline(steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", _build_calibrator(\n",
    "                base_est=xgb.XGBClassifier(\n",
    "                    n_estimators=400,\n",
    "                    max_depth=4,\n",
    "                    learning_rate=0.06,\n",
    "                    subsample=0.9,\n",
    "                    colsample_bytree=0.8,\n",
    "                    reg_lambda=1.0,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    eval_metric=\"logloss\",\n",
    "                    tree_method=\"hist\",\n",
    "                    random_state=seed,\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=scale_pos_weight\n",
    "                ),\n",
    "                method=calibrated(),\n",
    "                cv=3\n",
    "            ))\n",
    "        ])\n",
    "        models[\"XGB_cal\"] = xgb_cal\n",
    "\n",
    "    # 6) 可选：CatBoost（自身带概率，通常较稳，这里不额外校准）\n",
    "    if HAS_CAT:\n",
    "        cat = Pipeline(steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", CatBoostClassifier(\n",
    "                iterations=600,\n",
    "                depth=6,\n",
    "                learning_rate=0.05,\n",
    "                loss_function=\"Logloss\",\n",
    "                verbose=False,\n",
    "                random_state=seed\n",
    "            ))\n",
    "        ])\n",
    "        models[\"CatBoost\"] = cat\n",
    "\n",
    "    return models\n",
    "\n",
    "base_models = make_base_models(preprocessor, class_weight_dict, seed=SEED)\n",
    "list(base_models.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d6d3304-e8b9-4072-9a47-7a649a055cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] 生成 OOF 概率 ...\n",
      "[RF_cal] 生成 OOF 概率 ...\n",
      "[HGB_cal] 生成 OOF 概率 ...\n",
      "[LinearSVM_cal] 生成 OOF 概率 ...\n",
      "元特征维度（训练/测试）： (8000, 4) (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 得到每个基模型的 OOF 概率（训练元学习器）\n",
    "#         同时在全训数据上拟合一个最终基模型用于推理\n",
    "# ===================================================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "meta_train_list = []\n",
    "meta_test_list  = []\n",
    "fitted_bases = {}  # 存放全量拟合后的基模型\n",
    "\n",
    "for name, est in base_models.items():\n",
    "    print(f\"[{name}] 生成 OOF 概率 ...\")\n",
    "    # cross_val_predict 会对 fit_params 自动按训练索引切片\n",
    "    oof_proba = cross_val_predict(\n",
    "        est, X_train, y_train,\n",
    "        cv=skf,\n",
    "        method=\"predict_proba\",\n",
    "        n_jobs=None,\n",
    "        fit_params={\"clf__sample_weight\": sample_weight_train}\n",
    "    )\n",
    "    # 有些分类器的 predict_proba 只有两列（负类、正类）\n",
    "    if oof_proba.ndim == 2 and oof_proba.shape[1] == 2:\n",
    "        oof_pos = oof_proba[:, 1]\n",
    "    else:\n",
    "        oof_pos = oof_proba.ravel()\n",
    "    meta_train_list.append(oof_pos)\n",
    "\n",
    "    # 用全部训练集拟合一个最终版本，供测试/推理使用\n",
    "    est.fit(X_train, y_train, clf__sample_weight=sample_weight_train)\n",
    "    fitted_bases[name] = est\n",
    "\n",
    "    # 测试集上也给出对应的基模型概率，作为元特征\n",
    "    test_proba = est.predict_proba(X_test)\n",
    "    if test_proba.ndim == 2 and test_proba.shape[1] == 2:\n",
    "        test_pos = test_proba[:, 1]\n",
    "    else:\n",
    "        test_pos = test_proba.ravel()\n",
    "    meta_test_list.append(test_pos)\n",
    "\n",
    "# 组装元特征矩阵\n",
    "meta_X_train = np.vstack(meta_train_list).T\n",
    "meta_X_test  = np.vstack(meta_test_list).T\n",
    "\n",
    "print(\"元特征维度（训练/测试）：\", meta_X_train.shape, meta_X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753facbe-24c8-4bbf-a371-c955f812c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集概率（前10个）： [0.3746 0.3732 0.0982 0.1238 0.0982 0.1677 0.9899 0.3732 0.2694 0.3732]\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 元学习器训练（逻辑回归 + 轻量校准）\n",
    "# \n",
    "# ===================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import inspect\n",
    "\n",
    "# 若前面未定义 _build_calibrator，这里补充一个兼容性封装\n",
    "try:\n",
    "    _build_calibrator\n",
    "except NameError:\n",
    "    def _build_calibrator(base_est, method=\"isotonic\", cv=3):\n",
    "        \"\"\"\n",
    "        兼容性封装：sklearn>=1.2 使用 estimator，旧版本使用 base_estimator\n",
    "        \"\"\"\n",
    "        params = inspect.signature(CalibratedClassifierCV).parameters\n",
    "        if \"estimator\" in params:  # 新版\n",
    "            return CalibratedClassifierCV(estimator=base_est, method=method, cv=cv)\n",
    "        else:                      # 旧版\n",
    "            return CalibratedClassifierCV(base_estimator=base_est, method=method, cv=cv)\n",
    "\n",
    "# 元特征标准化\n",
    "meta_scaler = StandardScaler()\n",
    "meta_X_train_std = meta_scaler.fit_transform(meta_X_train)\n",
    "meta_X_test_std  = meta_scaler.transform(meta_X_test)\n",
    "\n",
    "# 元学习器：逻辑回归 + 轻量校准（小数据用 sigmoid，大数据用 isotonic）\n",
    "meta_base = LogisticRegression(max_iter=500, class_weight=class_weight_dict)\n",
    "cal_method = \"isotonic\" if len(X_train) >= 2000 else \"sigmoid\"\n",
    "meta_model = _build_calibrator(base_est=meta_base, method=cal_method, cv=3)\n",
    "\n",
    "# 训练（将样本权重传入以体现价值权重）\n",
    "meta_model.fit(meta_X_train_std, y_train, sample_weight=sample_weight_train)\n",
    "\n",
    "# 在测试集上的最终概率\n",
    "final_proba_test = meta_model.predict_proba(meta_X_test_std)[:, 1]\n",
    "print(\"测试集概率（前10个）：\", np.round(final_proba_test[:10], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d9d79a-a6f1-4f50-94df-0ed3d9038864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC      : 0.8616\n",
      "PR-AUC       : 0.6968\n",
      "Brier        : 0.1428\n",
      "ECE(15bins)  : 0.1750\n",
      "F1@0.5       : 0.6260  Precision@0.5: 0.5401  Recall@0.5: 0.7445\n",
      "Value-Precision@10%: 0.8389  Value-Recall@10%: 0.4126  价值覆盖率@10%: 0.1069\n",
      "Value-Precision@20%: 0.6648  Value-Recall@20%: 0.6220  价值覆盖率@20%: 0.2034\n",
      "价值加权 PR-AUC    : -0.7158\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 综合评估\n",
    "# ===================================================\n",
    "roc = roc_auc_score(y_test, final_proba_test)\n",
    "pr  = average_precision_score(y_test, final_proba_test)\n",
    "brier = brier_score_loss(y_test, final_proba_test)\n",
    "ece = expected_calibration_error(y_test, final_proba_test, n_bins=15)\n",
    "\n",
    "# F1 / 召回等（用 0.5 只是参考，真正业务阈值见下一单元格）\n",
    "pred_05 = (final_proba_test >= 0.5).astype(int)\n",
    "f1 = f1_score(y_test, pred_05)\n",
    "rec = recall_score(y_test, pred_05)\n",
    "prec = precision_score(y_test, pred_05)\n",
    "\n",
    "# 价值指标（以 v_test）\n",
    "v = v_test.values\n",
    "vp10, vr10, cov10 = value_precision_recall_at_k(y_test, final_proba_test, v, k=0.10)\n",
    "vp20, vr20, cov20 = value_precision_recall_at_k(y_test, final_proba_test, v, k=0.20)\n",
    "vpr_auc = value_pr_auc(y_test, final_proba_test, v)\n",
    "\n",
    "print(f\"ROC-AUC      : {roc:.4f}\")\n",
    "print(f\"PR-AUC       : {pr:.4f}\")\n",
    "print(f\"Brier        : {brier:.4f}\")\n",
    "print(f\"ECE(15bins)  : {ece:.4f}\")\n",
    "print(f\"F1@0.5       : {f1:.4f}  Precision@0.5: {prec:.4f}  Recall@0.5: {rec:.4f}\")\n",
    "print(f\"Value-Precision@10%: {vp10:.4f}  Value-Recall@10%: {vr10:.4f}  价值覆盖率@10%: {cov10:.4f}\")\n",
    "print(f\"Value-Precision@20%: {vp20:.4f}  Value-Recall@20%: {vr20:.4f}  价值覆盖率@20%: {cov20:.4f}\")\n",
    "print(f\"价值加权 PR-AUC    : {vpr_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21be4f29-a6fa-4222-9a36-027bbafff667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预算上限=10%，最优阈值 tau=0.9899，对应利润=0.21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>tau</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>-0.030327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995341</td>\n",
       "      <td>-0.356109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.989922</td>\n",
       "      <td>0.213056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.989922</td>\n",
       "      <td>0.042845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.989922</td>\n",
       "      <td>0.035628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k       tau    profit\n",
       "0  1  0.997313 -0.030327\n",
       "1  2  0.995341 -0.356109\n",
       "2  3  0.989922  0.213056\n",
       "3  4  0.989922  0.042845\n",
       "4  5  0.989922  0.035628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 利润驱动的阈值搜索（带预算）\n",
    "# 可调参数：\n",
    "#   C_contact：联系成本（单位化即可）\n",
    "#   gain     ：成功挽留时的收益系数（乘以客户价值 v_i）\n",
    "#   budget   ：最多联系的比例（例如 10%）\n",
    "# ===================================================\n",
    "C_contact = 1.0\n",
    "gain = 2.0\n",
    "budget = 0.10  # 只联系前 10%\n",
    "\n",
    "best_tau, best_profit, profit_curve = search_tau_by_profit(\n",
    "    scores=final_proba_test,\n",
    "    y_true=y_test,\n",
    "    v=v_test.values,\n",
    "    C_contact=C_contact,\n",
    "    gain=gain,\n",
    "    budget=budget\n",
    ")\n",
    "\n",
    "print(f\"预算上限={int(budget*100)}%，最优阈值 tau={best_tau:.4f}，对应利润={best_profit:.2f}\")\n",
    "profit_curve.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5ef2037-f9d7-40b7-8236-99bd376ae4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10%：Value-Precision=0.8389  Value-Recall=0.4126  覆盖率=0.1069  利润=-43.90\n",
      "阈值 tau=0.9899：  选中人数=35  利润=-4.36\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 按照最优阈值或 Top-K 进行选客，并输出业务汇总\n",
    "# ===================================================\n",
    "scores = final_proba_test.copy()\n",
    "order = np.argsort(-scores)\n",
    "k = max(1, int(math.floor(budget * len(scores))))\n",
    "sel_idx = order[:k]\n",
    "\n",
    "y_sel = y_test[sel_idx]\n",
    "v_sel = v_test.values[sel_idx]\n",
    "\n",
    "# 价值指标（Top-K）\n",
    "vp, vr, cov = value_precision_recall_at_k(y_test, scores, v_test.values, k=budget)\n",
    "# 利润（Top-K）\n",
    "profit_topk = gain * (v_sel[y_sel == 1].sum()) - C_contact * len(sel_idx)\n",
    "\n",
    "# 利润（最优阈值）\n",
    "sel_tau = np.where(scores >= best_tau)[0]\n",
    "profit_tau = gain * (v_test.values[sel_tau][y_test[sel_tau] == 1].sum()) - C_contact * len(sel_tau)\n",
    "\n",
    "print(f\"Top-{int(budget*100)}%：Value-Precision={vp:.4f}  Value-Recall={vr:.4f}  覆盖率={cov:.4f}  利润={profit_topk:.2f}\")\n",
    "print(f\"阈值 tau={best_tau:.4f}：  选中人数={len(sel_tau)}  利润={profit_tau:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c0390d8-8188-4ad9-b51a-84e01ab6e569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "封装模型测试概率（前5个）： [0.3746 0.3732 0.0982 0.1238 0.0982]\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 可复用封装（训练 -> 预测 -> 选客）\n",
    "# 为兼容 sklearn 新旧版本，这里提供 _build_calibrator 封装\n",
    "# ===================================================\n",
    "from dataclasses import dataclass\n",
    "import joblib\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# ---- 兼容封装：sklearn>=1.2 使用 estimator，旧版使用 base_estimator ----\n",
    "def _build_calibrator(base_est, method=\"isotonic\", cv=3):\n",
    "    params = inspect.signature(CalibratedClassifierCV).parameters\n",
    "    if \"estimator\" in params:  # 新版\n",
    "        return CalibratedClassifierCV(estimator=base_est, method=method, cv=cv)\n",
    "    else:                      # 旧版\n",
    "        return CalibratedClassifierCV(base_estimator=base_est, method=method, cv=cv)\n",
    "\n",
    "@dataclass\n",
    "class VStackConfig:\n",
    "    seed: int = SEED\n",
    "    gamma: float = 1.0\n",
    "    n_splits: int = 5\n",
    "    calibrate_method: str = \"auto\"  # 'auto' / 'isotonic' / 'sigmoid'\n",
    "    class_weight: dict = None\n",
    "\n",
    "class VStackChurnModel:\n",
    "    def __init__(self, preprocessor, config: VStackConfig):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.cfg = config\n",
    "        self.base_models = None\n",
    "        self.fitted_bases = None\n",
    "        self.meta_scaler = None\n",
    "        self.meta_model = None\n",
    "\n",
    "    def _make_bases(self):\n",
    "        # 复用前面单元格中定义的 make_base_models（已内置校准）\n",
    "        return make_base_models(self.preprocessor, self.cfg.class_weight, seed=self.cfg.seed)\n",
    "\n",
    "    def fit(self, X, y, v, sample_weight):\n",
    "        \"\"\"\n",
    "        X, y：训练集\n",
    "        v：客户价值（目前未直接用到，保留以便扩展）\n",
    "        sample_weight：样本权重（已包含类别不平衡与价值权重）\n",
    "        \"\"\"\n",
    "        self.base_models = self._make_bases()\n",
    "        skf = StratifiedKFold(n_splits=self.cfg.n_splits, shuffle=True, random_state=self.cfg.seed)\n",
    "\n",
    "        meta_train = []\n",
    "        self.fitted_bases = {}\n",
    "        for name, est in self.base_models.items():\n",
    "            # 生成 OOF 概率作为元特征\n",
    "            oof = cross_val_predict(\n",
    "                est, X, y, cv=skf, method=\"predict_proba\",\n",
    "                fit_params={\"clf__sample_weight\": sample_weight}\n",
    "            )\n",
    "            oof = oof[:, 1] if oof.ndim == 2 else oof.ravel()\n",
    "            meta_train.append(oof)\n",
    "\n",
    "            # 在全量训练集上拟合一个最终基模型供推理使用\n",
    "            est.fit(X, y, clf__sample_weight=sample_weight)\n",
    "            self.fitted_bases[name] = est\n",
    "\n",
    "        # 组装并标准化元特征\n",
    "        meta_train = np.vstack(meta_train).T\n",
    "        self.meta_scaler = StandardScaler()\n",
    "        meta_train_std = self.meta_scaler.fit_transform(meta_train)\n",
    "\n",
    "        # 元学习器：逻辑回归 + 轻量校准（小数据用 sigmoid，大数据用 isotonic）\n",
    "        base = LogisticRegression(max_iter=500, class_weight=self.cfg.class_weight)\n",
    "        cal_method = \"isotonic\" if len(X) >= 2000 else \"sigmoid\"\n",
    "        self.meta_model = _build_calibrator(base_est=base, method=cal_method, cv=3)\n",
    "        self.meta_model.fit(meta_train_std, y, sample_weight=sample_weight)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"使用拟合好的基模型得到元特征 -> 元学习器概率\"\"\"\n",
    "        meta_list = []\n",
    "        for name in self.fitted_bases:\n",
    "            p = self.fitted_bases[name].predict_proba(X)\n",
    "            p = p[:, 1] if p.ndim == 2 else p.ravel()\n",
    "            meta_list.append(p)\n",
    "        meta = np.vstack(meta_list).T\n",
    "        meta_std = self.meta_scaler.transform(meta)\n",
    "        return self.meta_model.predict_proba(meta_std)[:, 1]\n",
    "\n",
    "    def select_by_budget(self, X, y, v, C_contact=1.0, gain=2.0, budget=0.1):\n",
    "        \"\"\"\n",
    "        按预算上限在集合 X 中选择客户：\n",
    "        返回 (最优阈值 tau, 最优利润, 选中索引, 概率分数, 利润曲线DataFrame)\n",
    "        \"\"\"\n",
    "        scores = self.predict_proba(X)\n",
    "        tau, best_profit, curve = search_tau_by_profit(scores, y, v, C_contact, gain, budget)\n",
    "        idx_tau = np.where(scores >= tau)[0]\n",
    "        return tau, best_profit, idx_tau, scores, curve\n",
    "\n",
    "    def save(self, path):\n",
    "        obj = {\n",
    "            \"preprocessor\": self.preprocessor,\n",
    "            \"fitted_bases\": self.fitted_bases,\n",
    "            \"meta_scaler\": self.meta_scaler,\n",
    "            \"meta_model\": self.meta_model,\n",
    "            \"config\": self.cfg,\n",
    "        }\n",
    "        joblib.dump(obj, path)\n",
    "        return path\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        obj = joblib.load(path)\n",
    "        model = VStackChurnModel(obj[\"preprocessor\"], obj[\"config\"])\n",
    "        model.fitted_bases = obj[\"fitted_bases\"]\n",
    "        model.meta_scaler = obj[\"meta_scaler\"]\n",
    "        model.meta_model = obj[\"meta_model\"]\n",
    "        return model\n",
    "\n",
    "# ====== 使用示例（可按需重训/保存）======\n",
    "cfg = VStackConfig(seed=SEED, gamma=gamma, class_weight=class_weight_dict)\n",
    "vstack_model = VStackChurnModel(preprocessor, cfg).fit(X_train, y_train, v_train.values, sample_weight_train)\n",
    "proba_check = vstack_model.predict_proba(X_test)[:5]\n",
    "print(\"封装模型测试概率（前5个）：\", np.round(proba_check, 4))\n",
    "\n",
    "# 保存（可选）\n",
    "# path = \"vstack_churn_model.joblib\"\n",
    "# vstack_model.save(path)\n",
    "# print(\"已保存到：\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca24671-a81b-415c-816e-84a311fa764c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
