{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3e4322",
   "metadata": {},
   "source": [
    "# KDD Cup 2009 – Churn Dataset EDA\n",
    "\n",
    "This notebook performs an **Exploratory Data Analysis (EDA)** on the **KDD Cup 2009 churn prediction dataset** (`KDDCup09_churn.arff`).\n",
    "\n",
    "Goals of this notebook:\n",
    "- Load the ARFF file and convert it into a clean `pandas` DataFrame\n",
    "- Inspect basic structure (shape, dtypes, target distribution)\n",
    "- Understand missing values and data quality issues\n",
    "- Explore numerical and categorical features\n",
    "- Provide visualizations that will be re-usable in the thesis\n",
    "\n",
    "> **Note:** This notebook is written in English and designed to be self-explanatory, so it can be directly referenced in your thesis appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4d798",
   "metadata": {},
   "source": [
    "## 1. Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5719f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m arff\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_columns\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m50\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "# Make plots a bit larger\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf33e7",
   "metadata": {},
   "source": [
    "## 2. Load the ARFF file\n",
    "\n",
    "The dataset is provided in **ARFF** format. We use `scipy.io.arff.loadarff` to read it.\n",
    "\n",
    "Please make sure the file `KDDCup09_churn.arff` is in the same folder as this notebook or update the `data_path` variable accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f99317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'KDDCup09_churn.arff'  # change this path if needed\n",
    "\n",
    "data, meta = arff.loadarff(data_path)\n",
    "df_raw = pd.DataFrame(data)\n",
    "\n",
    "print('Raw shape:', df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602b51b",
   "metadata": {},
   "source": [
    "## 3. Basic cleaning\n",
    "\n",
    "The ARFF loader reads string attributes as Python `bytes` objects and uses the `'?'` symbol for missing values. The target column is named **`CHURN`** with values `b'1'` and `b'-1'`.\n",
    "\n",
    "We will:\n",
    "- Convert all `bytes` columns to regular Python strings\n",
    "- Replace `'?'` with proper `NaN`\n",
    "- Map `CHURN` from `{b'1', b'-1'}` to a binary label `{1, 0}`\n",
    "- Rename the target column to `churn` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de961d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# 3.1 Convert bytes to strings where necessary\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "# 3.2 Standardize missing values\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# 3.3 Handle target variable\n",
    "if 'CHURN' in df.columns:\n",
    "    df['churn'] = df['CHURN'].map({'1': 1, '-1': 0}).astype('Int64')\n",
    "    df.drop(columns=['CHURN'], inplace=True)\n",
    "else:\n",
    "    raise KeyError('CHURN column not found in the dataset')\n",
    "\n",
    "print('Cleaned shape:', df.shape)\n",
    "df[['churn']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a82cf0",
   "metadata": {},
   "source": [
    "## 4. Dataset structure and target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037046a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "print(f'Number of rows: {n_rows}')\n",
    "print(f'Number of columns (including target): {n_cols}')\n",
    "\n",
    "print('\\nData types summary:')\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print('\\nTarget distribution (churn):')\n",
    "print(df['churn'].value_counts(dropna=False))\n",
    "print('\\nChurn rate:', df['churn'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afe33b",
   "metadata": {},
   "source": [
    "## 5. Numerical vs categorical features\n",
    "\n",
    "We separate numerical and categorical predictors. The target `churn` is excluded from the feature lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0626ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c != 'churn']\n",
    "\n",
    "num_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols = [c for c in feature_cols if c not in num_cols]\n",
    "\n",
    "print(f'Numerical features: {len(num_cols)}')\n",
    "print(f'Categorical features: {len(cat_cols)}')\n",
    "\n",
    "num_cols[:10], cat_cols[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b40425",
   "metadata": {},
   "source": [
    "## 6. Missing values analysis\n",
    "\n",
    "The KDD churn dataset is known to be **noisy** and to contain many missing values.\n",
    "\n",
    "We compute the missing rate per column and visualize the top columns with the largest amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = df[feature_cols].isna().sum()\n",
    "missing_pct = (missing_counts / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({'missing_count': missing_counts, 'missing_pct': missing_pct})\n",
    "missing_df.sort_values('missing_pct', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc404c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 20 features by missing percentage\n",
    "top_missing = missing_df.sort_values('missing_pct', ascending=False).head(20)\n",
    "\n",
    "plt.figure()\n",
    "top_missing['missing_pct'].sort_values().plot(kind='barh')\n",
    "plt.xlabel('Missing percentage (%)')\n",
    "plt.title('Top 20 features with highest missing rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fdbdf",
   "metadata": {},
   "source": [
    "## 7. Numerical features – summary statistics\n",
    "\n",
    "We compute basic descriptive statistics for numerical variables and inspect a few of them.\n",
    "Given the large number of features, we show only the first 10 columns by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b816e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_summary = df[num_cols].describe().T\n",
    "num_summary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700ce48",
   "metadata": {},
   "source": [
    "### 7.1 Histograms for selected numerical features\n",
    "\n",
    "To get an idea of the distribution shapes, we plot histograms for a small subset of numerical variables.\n",
    "Each plot is generated in a separate figure (no subplots), in line with the plotting constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num_cols = num_cols[:6]  # adjust if you want more/others\n",
    "\n",
    "for col in sample_num_cols:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd02f7",
   "metadata": {},
   "source": [
    "### 7.2 Correlation heatmap (subset of numerical features)\n",
    "\n",
    "Because the dataset has many numerical features, computing a full correlation matrix may be heavy.\n",
    "We select up to 30 numerical features to visualize their pairwise correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_num_cols = num_cols[:30]\n",
    "corr_matrix = df[subset_num_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr_matrix, aspect='auto')\n",
    "plt.xticks(range(len(subset_num_cols)), subset_num_cols, rotation=90)\n",
    "plt.yticks(range(len(subset_num_cols)), subset_num_cols)\n",
    "plt.colorbar(label='Correlation')\n",
    "plt.title('Correlation heatmap (subset of numerical features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9a297",
   "metadata": {},
   "source": [
    "## 8. Categorical features – cardinality and frequency\n",
    "\n",
    "We inspect categorical features to understand their cardinality (number of distinct levels) and the distribution of the most frequent categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cardinality = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "cat_cardinality.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 categorical variables by cardinality\n",
    "plt.figure()\n",
    "cat_cardinality.head(15).sort_values().plot(kind='barh')\n",
    "plt.xlabel('Number of unique categories')\n",
    "plt.title('Top categorical features by cardinality')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39b6118",
   "metadata": {},
   "source": [
    "### 8.1 Category frequency plots\n",
    "\n",
    "We visualize the top categories for a small set of categorical variables.\n",
    "This helps to see whether some variables are dominated by a few levels or are more evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83214b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cat_cols = cat_cols[:4]  # adjust as needed\n",
    "\n",
    "for col in sample_cat_cols:\n",
    "    plt.figure()\n",
    "    df[col].value_counts(dropna=False).head(10).plot(kind='bar')\n",
    "    plt.title(f'Top 10 categories for {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b7dc6",
   "metadata": {},
   "source": [
    "## 9. Target vs. features (preliminary insights)\n",
    "\n",
    "Finally, we perform a few quick checks of how some features differ between churners and non-churners.\n",
    "Here we only use simple groupby statistics for illustration; detailed modeling will be done in separate notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: compare mean of a few numerical features by churn status\n",
    "example_num_cols = num_cols[:5]\n",
    "df.groupby('churn')[example_num_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac67d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: distribution of a categorical variable by churn\n",
    "if sample_cat_cols:\n",
    "    col = sample_cat_cols[0]\n",
    "    ctab = pd.crosstab(df[col], df['churn'], normalize='index')\n",
    "    ctab.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74f288a",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "In this notebook we:\n",
    "- Loaded the KDD Cup 2009 churn dataset from an ARFF file\n",
    "- Converted raw bytes and placeholder missing values into a clean `pandas` DataFrame\n",
    "- Explored the dataset structure, including the strong class imbalance of the `churn` label\n",
    "- Analyzed missing values, confirming that the dataset is **noisy** with many incomplete features\n",
    "- Separated numerical and categorical variables and examined their distributions\n",
    "- Visualized correlations and category frequencies to build intuition for later feature engineering and modeling\n",
    "\n",
    "This EDA provides the empirical motivation for applying robust, cost-sensitive models and careful pre-processing steps in the main experiments of the thesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
