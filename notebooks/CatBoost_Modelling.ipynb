{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1aaaa6",
   "metadata": {},
   "source": [
    "# CatBoost Baseline for Bank Customer Churn (English Version)\n",
    "\n",
    "This notebook implements a **CatBoost baseline model** for bank customer churn prediction.\n",
    "It follows the experimental requirements from the slides and reports the following metrics:\n",
    "\n",
    "- ROC-AUC\n",
    "- PR-AUC (Average Precision)\n",
    "- F1-score\n",
    "- Balanced Accuracy\n",
    "- Brier Score\n",
    "- Top-K metrics: Precision@K / Recall@K (default: top 10% highest-risk customers)\n",
    "\n",
    "Adjust `DATA_PATH` to your actual dataset location. The example assumes a Kaggle-style bank churn dataset with a binary churn label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5358d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Environment & dependencies\n",
    "#!pip install catboost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    brier_score_loss,\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 2025\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Default path; change if needed\n",
    "DATA_PATH = Path('churn_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "446f240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load data\n",
    "assert DATA_PATH.exists(), f\"Data file not found: {DATA_PATH}. Please check the path.\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2cf90",
   "metadata": {},
   "source": [
    "## 2. Define features and target\n",
    "\n",
    "- Assumed target column: `Exited` (0 = retained, 1 = churn), or similar.\n",
    "- Drop ID-like columns such as `RowNumber`, `CustomerId`, `CustomerID`, `Surname` if they exist.\n",
    "- Use CatBoost native categorical handling: pass categorical feature indices via `cat_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0d6a05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: Exited\n",
      "Dropping ID-like columns: []\n",
      "Categorical feature indices: [1, 2]\n",
      "Categorical feature names: ['Geography', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Identify target column\n",
    "target_col_candidates = [c for c in df.columns if c.lower() in ['exited', 'churn', 'attrition_flag']]\n",
    "assert len(target_col_candidates) == 1, (\n",
    "    'Unable to uniquely identify target column. '\n",
    "    f'Candidates: {target_col_candidates}. Columns: {df.columns.tolist()}'\n",
    ")\n",
    "TARGET_COL = target_col_candidates[0]\n",
    "print('Target column:', TARGET_COL)\n",
    "\n",
    "# 2.2 Drop ID-like columns (if present)\n",
    "drop_cols = [c for c in df.columns if c.lower() in ['rownumber', 'customerid', 'customer_id', 'surname']]\n",
    "print('Dropping ID-like columns:', drop_cols)\n",
    "\n",
    "df_model = df.drop(columns=drop_cols)\n",
    "\n",
    "# 2.3 Split into features and label\n",
    "X = df_model.drop(columns=[TARGET_COL])\n",
    "y = df_model[TARGET_COL].astype(int)\n",
    "\n",
    "# 2.4 Detect categorical features by dtype\n",
    "cat_features = [i for i, c in enumerate(X.columns)\n",
    "                if X[c].dtype == 'object' or str(X[c].dtype).startswith('category')]\n",
    "print('Categorical feature indices:', cat_features)\n",
    "print('Categorical feature names:', [X.columns[i] for i in cat_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fba627",
   "metadata": {},
   "source": [
    "## 3. Train / test split\n",
    "\n",
    "- Stratified split to preserve churn rate.\n",
    "- 60/20/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "774b4fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6000, 10) Target ratio: 0.2037\n",
      "Validation shape: (2000, 10) Target ratio: 0.204\n",
      "Test shape: (2000, 10) Target ratio: 0.2035\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.4,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_temp,\n",
    ")\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Target ratio:', y_train.mean().round(4))\n",
    "print('Validation shape:', X_val.shape, 'Target ratio:', y_val.mean().round(4))\n",
    "print('Test shape:', X_test.shape, 'Target ratio:', y_test.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2df9db",
   "metadata": {},
   "source": [
    "## 4. Evaluation utilities (including Top-K metrics)\n",
    "\n",
    "Top-K metrics definition:\n",
    "- Let **K** be a proportion (e.g., 10%) of the test set with the highest predicted churn probabilities.\n",
    "- **Precision@K**: fraction of true churners among the top-K ranked customers.\n",
    "- **Recall@K**: fraction of all churners covered by the top-K ranked customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d0b08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_precision_recall(y_true, y_proba, k_ratio: float = 0.1):\n",
    "    \"\"\"Compute Precision@K and Recall@K, where K = k_ratio * N (at least 1).\n",
    "\n",
    "    Args:\n",
    "        y_true: array-like of shape (n_samples,), binary ground truth (0/1).\n",
    "        y_proba: array-like of shape (n_samples,), predicted probabilities for the positive class.\n",
    "        k_ratio: float in (0, 1], fraction of samples to select as top-K.\n",
    "    \"\"\"\n",
    "    assert 0 < k_ratio <= 1, \"k_ratio must be in (0, 1].\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_proba = np.asarray(y_proba)\n",
    "\n",
    "    n = len(y_true)\n",
    "    k = max(1, int(np.floor(n * k_ratio)))\n",
    "\n",
    "    # sort indices by predicted probability (descending)\n",
    "    order = np.argsort(-y_proba)\n",
    "    topk_idx = order[:k]\n",
    "\n",
    "    y_topk = y_true[topk_idx]\n",
    "    tp_at_k = y_topk.sum()\n",
    "    total_positives = y_true.sum()\n",
    "\n",
    "    precision_at_k = tp_at_k / k\n",
    "    recall_at_k = tp_at_k / total_positives if total_positives > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        'K': k,\n",
    "        'Precision@K': precision_at_k,\n",
    "        'Recall@K': recall_at_k,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_classifier(y_true, y_proba, threshold: float = 0.5, k_ratio: float = 0.1):\n",
    "    \"\"\"Compute all required metrics for a binary classifier.\n",
    "\n",
    "    Returns a dictionary containing:\n",
    "    ROC-AUC, PR-AUC, F1, Balanced Accuracy, Brier Score, K, Precision@K, Recall@K.\n",
    "    \"\"\"\n",
    "    y_true_arr = y_true.values if isinstance(y_true, pd.Series) else np.asarray(y_true)\n",
    "    y_proba_arr = np.asarray(y_proba)\n",
    "\n",
    "    # Threshold-based predictions\n",
    "    y_pred = (y_proba_arr >= threshold).astype(int)\n",
    "\n",
    "    # Core metrics\n",
    "    roc = roc_auc_score(y_true_arr, y_proba_arr)\n",
    "    pr_auc = average_precision_score(y_true_arr, y_proba_arr)\n",
    "    f1 = f1_score(y_true_arr, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true_arr, y_pred)\n",
    "    brier = brier_score_loss(y_true_arr, y_proba_arr)\n",
    "\n",
    "    # Top-K metrics\n",
    "    topk = topk_precision_recall(y_true_arr, y_proba_arr, k_ratio=k_ratio)\n",
    "\n",
    "    metrics = {\n",
    "        'ROC-AUC': roc,\n",
    "        'PR-AUC': pr_auc,\n",
    "        'F1': f1,\n",
    "        'BalancedAccuracy': bal_acc,\n",
    "        'BrierScore': brier,\n",
    "        'K': topk['K'],\n",
    "        'Precision@K': topk['Precision@K'],\n",
    "        'Recall@K': topk['Recall@K'],\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275553d",
   "metadata": {},
   "source": [
    "## 5. Train CatBoost baseline model\n",
    "\n",
    "Design choices:\n",
    "- Use class weights to handle label imbalance (computed from training set).\n",
    "- Reasonable depth and number of estimators.\n",
    "- Enable early stopping based on validation AUC.\n",
    "- Keep it **strong but still a baseline**, without heavy tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49799062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio = 0.2037, scale_pos_weight = 3.910\n",
      "CatBoost baseline model trained. Best iteration: 127\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Compute class weight for positive class\n",
    "pos_frac = y_train.mean()\n",
    "neg_frac = 1 - pos_frac\n",
    "scale_pos_weight = float(neg_frac / pos_frac)\n",
    "print(f\"Positive ratio = {pos_frac:.4f}, scale_pos_weight = {scale_pos_weight:.3f}\")\n",
    "\n",
    "# 5.2 Define CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    n_estimators=2000,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    class_weights=[1.0, scale_pos_weight],  # [negative, positive]\n",
    "    od_type='Iter',         # early stopping\n",
    "    od_wait=50,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# 5.3 Fit model using native categorical handling and validation set\n",
    "cat_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_val, y_val),\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "best_iter = getattr(cat_model, 'get_best_iteration', lambda: -1)()\n",
    "if best_iter is not None and best_iter >= 0:\n",
    "    print(f'CatBoost baseline model trained. Best iteration: {best_iter}')\n",
    "else:\n",
    "    print('CatBoost baseline model trained.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387a2f4",
   "metadata": {},
   "source": [
    "## 6. Evaluate on the test set\n",
    "\n",
    "- Use predicted probabilities from `predict_proba`.\n",
    "- Default decision threshold: 0.5 (can be optimized later using cost/benefit analysis).\n",
    "- Default Top-K ratio: 10% of test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bffb149c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>BalancedAccuracy</th>\n",
       "      <th>BrierScore</th>\n",
       "      <th>K</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>Recall@K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Validation</td>\n",
       "      <td>0.876752</td>\n",
       "      <td>0.715782</td>\n",
       "      <td>0.621730</td>\n",
       "      <td>0.791679</td>\n",
       "      <td>0.137171</td>\n",
       "      <td>200</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.406863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.869734</td>\n",
       "      <td>0.718839</td>\n",
       "      <td>0.611222</td>\n",
       "      <td>0.784925</td>\n",
       "      <td>0.137454</td>\n",
       "      <td>200</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.420147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset   ROC-AUC    PR-AUC        F1  BalancedAccuracy  BrierScore  \\\n",
       "0  Validation  0.876752  0.715782  0.621730          0.791679    0.137171   \n",
       "1        Test  0.869734  0.718839  0.611222          0.784925    0.137454   \n",
       "\n",
       "     K  Precision@K  Recall@K  \n",
       "0  200        0.830  0.406863  \n",
       "1  200        0.855  0.420147  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_proba = cat_model.predict_proba(X_val)[:, 1]\n",
    "y_test_proba = cat_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics_val = evaluate_classifier(y_val, y_val_proba, threshold=0.5, k_ratio=0.1)\n",
    "metrics_test = evaluate_classifier(y_test, y_test_proba, threshold=0.5, k_ratio=0.1)\n",
    "\n",
    "metrics_df = pd.DataFrame([\n",
    "    {'Dataset': 'Validation', **metrics_val},\n",
    "    {'Dataset': 'Test', **metrics_test},\n",
    "])\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1b57e",
   "metadata": {},
   "source": [
    "The CatBoost baseline model achieved stable and strong performance across both validation and test sets.\n",
    "ROC-AUC and PR-AUC indicate excellent discrimination ability, while F1 and Balanced Accuracy show consistent classification effectiveness.\n",
    "The Top-K analysis (Precision@10% = 0.855) demonstrates high practical value for targeted retention strategies, identifying over 42% of potential churners among the top 10% highest-risk customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad2b83",
   "metadata": {},
   "source": [
    "## 7. Export results \n",
    "\n",
    "To facilitate comparison with other baseline models (Logistic Regression, Random Forest, XGBoost, LightGBM, SVM):\n",
    "\n",
    "- Save the metric summary as CSV.\n",
    "- Save test-set probabilities for calibration plots, lift curves, and cost-sensitive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84136f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('models/catboost_baseline.joblib')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR = Path('models')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH = MODEL_DIR / 'catboost_baseline.joblib'\n",
    "joblib.dump(cat_model, MODEL_PATH)\n",
    "MODEL_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a509d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported metrics and predictions to: reports\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = Path('reports')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# 7.1 Save metric summary for validation and test splits\n",
    "metrics_df.to_csv(OUTPUT_DIR / 'catboost_baseline_metrics_en.csv', index=False)\n",
    "\n",
    "# 7.2 Save predictions (dataset label, y_true and probabilities)\n",
    "pred_val = pd.DataFrame({\n",
    "    'dataset': ['validation'] * len(y_val),\n",
    "    'y_true': y_val.values,\n",
    "    'y_proba': y_val_proba,\n",
    "})\n",
    "pred_test = pd.DataFrame({\n",
    "    'dataset': ['test'] * len(y_test),\n",
    "    'y_true': y_test.values,\n",
    "    'y_proba': y_test_proba,\n",
    "})\n",
    "pred_df = pd.concat([pred_val, pred_test], ignore_index=True)\n",
    "pred_df.to_csv(OUTPUT_DIR / 'catboost_baseline_predictions_en.csv', index=False)\n",
    "\n",
    "print('Exported metrics and predictions to:', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82f5e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customerCHurnerVENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
