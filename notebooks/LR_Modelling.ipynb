{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline (60/20/20 split)\n",
    "\n",
    "Lightweight notebook that trains and evaluates a logistic regression classifier on the churn dataset using a 60% train / 20% validation / 20% test split—no SMOTE, no grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('churn_clean.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude='object').columns.tolist()\n",
    "cat_cols, num_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train/Validation/Test Split (60/20/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.4,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=y_temp,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print('Train:', X_train.shape, 'Target ratio:', y_train.mean().round(3))\n",
    "print('Validation:', X_val.shape, 'Target ratio:', y_val.mean().round(3))\n",
    "print('Test:', X_test.shape, 'Target ratio:', y_test.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('categorical', ohe, cat_cols),\n",
    "    ('numeric', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        solver='liblinear',\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "log_reg_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "log_reg_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate on Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = log_reg_pipeline.predict(X_val)\n",
    "y_val_proba = log_reg_pipeline.predict_proba(X_val)[:, 1]\n",
    "y_test_pred = log_reg_pipeline.predict(X_test)\n",
    "y_test_proba = log_reg_pipeline.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation ROC-AUC:', round(roc_auc_score(y_val, y_val_proba), 3))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print('Test ROC-AUC:', round(roc_auc_score(y_test, y_test_proba), 3))\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cm = confusion_matrix(y_val, y_val_pred)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "val_cm, test_cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Visual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_DIR = Path('figures')\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fpr, val_tpr, _ = roc_curve(y_val, y_val_proba)\n",
    "test_fpr, test_tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "val_prec, val_rec, _ = precision_recall_curve(y_val, y_val_proba)\n",
    "test_prec, test_rec, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "val_ap = average_precision_score(y_val, y_val_proba)\n",
    "test_ap = average_precision_score(y_test, y_test_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(val_fpr, val_tpr, label=f'Validation AUC = {val_auc:.3f}')\n",
    "plt.plot(test_fpr, test_tpr, label=f'Test AUC = {test_auc:.3f}', linestyle='--')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve — Logistic Regression Baseline')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'roc_curve_logreg_baseline.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(val_rec, val_prec, label=f'Validation AP = {val_ap:.3f}')\n",
    "plt.plot(test_rec, test_prec, label=f'Test AP = {test_ap:.3f}', linestyle='--')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision–Recall Curve — Logistic Regression Baseline')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'pr_curve_logreg_baseline.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "sns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\n",
    "axes[0].set_title('Validation Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "sns.heatmap(test_cm, annot=True, fmt='d', cmap='Greens', cbar=False, ax=axes[1])\n",
    "axes[1].set_title('Test Confusion Matrix')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'confusion_matrices_logreg_baseline.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Inspect Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = log_reg_pipeline.named_steps['model'].coef_[0]\n",
    "feature_names = log_reg_pipeline.named_steps['preprocess'].get_feature_names_out()\n",
    "coef_series = pd.Series(coef, index=feature_names)\n",
    "coef_series.sort_values(key=lambda s: s.abs(), ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Persist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path('models')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH = MODEL_DIR / 'log_reg_baseline.joblib'\n",
    "joblib.dump(log_reg_pipeline, MODEL_PATH)\n",
    "MODEL_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Notes\n",
    "\n",
    "- Pipeline keeps preprocessing and model together for easy reuse.\n",
    "- Validation metrics help tune decision thresholds before touching the hold-out test set.\n",
    "- Saved joblib file can be reloaded with `joblib.load(MODEL_PATH)` to score new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customerCHurnerVENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
